<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mind On The Ball</title>
    <description>Welcome to Mind On The Ball. We want to teach you about neural nets through fantasy football data.
</description>
    <link>http://yourdomain.com/blog/</link>
    <atom:link href="http://yourdomain.com/blog/feed.xml" rel="self" type="application/rss+xml"/>

    <pubDate>Mon, 28 Nov 2016 17:04:50 -0700</pubDate>
    <lastBuildDate>Mon, 28 Nov 2016 17:04:50 -0700</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Neural Net Basics and Forward Propagation</title>
        <description>&lt;h2 id=&quot;what-is-a-neural-net&quot;&gt;What is a Neural Net?&lt;/h2&gt;

&lt;p&gt;A Neural Net at its most basic level is a machine learning algorithm that uses a series of “decision-making” nodes to predict an outcome.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;When researching we found this literature to be very helpful and would encourage anyone who is interested in building a neural net to check it out: &lt;a href=&quot;http://neuralnetworksanddeeplearning.com/about.html&quot;&gt;link to Neural Net and Deep Learning book&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;basic-architecture&quot;&gt;Basic Architecture&lt;/h2&gt;

&lt;p&gt;All Neural Nets must have at least two layers, an input layer (where data is introduced to the net, either training data, or data used in making a prediction), and an output layer (result of the input layer data moving through the net). However, most neural nets contain one or more hidden layers of decision making nodes as well. In the case of our neural net, we included one hidden layer.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Since the players in our database all have twelve possible statistical categories, we knew we would need at least twelve input nodes, one for each value. In order to make predictions based on the previous four game stats for a player, we had to multiply the number of input nodes by four, giving us a total of forty-eight input nodes.&lt;/li&gt;
  &lt;li&gt;The output layer remains twelve nodes, one for each stat category, since we only want to predict one “week” of data. The hidden layer size was determined less mathematically than the others.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It was suggested based on our research to choose a number roughly halfway between the input and output layers, so we chose a node count of thirty. This hidden layer works behind the scenes and is the “magic” of the neural net. Fortunately, the specific node count in this layer is arbitrary in a sense, provided that the node count is within a reasonable range.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;This provided us with a neural net with the shape of [48 x 30 x 12]. Below is an image of a [3 x 4 x 1] neural net:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://neuralnetworksanddeeplearning.com/images/tikz1.png&quot; alt=&quot;Architecture&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;input-layer&quot;&gt;Input Layer&lt;/h3&gt;

&lt;p&gt;The values in this layer are essentially a likelihood of something occurring, so any input value must be between a 0 and 100% likelihood.&lt;/p&gt;

&lt;h4 id=&quot;data-normalization&quot;&gt;Data Normalization&lt;/h4&gt;

&lt;p&gt;Since inputs are a probability, they need to be normalized based on some criteria. In the case of our net, we looked up the current NFL record in each category, and determined our 100% max value by padding each record with some extra values in an attempt to make the ceiling be just out of reach of what seems possible to achieve.&lt;/p&gt;

&lt;p&gt;We then compare the input value with our maximum calculated value and zero, to grant a percentage. For example, if the max passing yards was determined to be 800 yards, and a player throws for 400 yards, their normalized passing yards would be input to the net as 800 / 400 = 0.5.&lt;/p&gt;

&lt;h3 id=&quot;hidden-layer&quot;&gt;Hidden Layer&lt;/h3&gt;

&lt;p&gt;The hidden layer has an inherent uncertainty.&lt;/p&gt;

&lt;h3 id=&quot;output-layer&quot;&gt;Output Layer&lt;/h3&gt;

&lt;h2 id=&quot;assigning-weights-and-biases&quot;&gt;Assigning Weights and Biases&lt;/h2&gt;

&lt;p&gt;Will explain importance of weights and biases, but will make sure to highlight that the magic of NN is that these will morph based on f and b prop, so the initial values just need to be random&lt;/p&gt;

&lt;h3 id=&quot;sigmoid&quot;&gt;Sigmoid&lt;/h3&gt;

&lt;p&gt;and will then go over our choice for sigmoid.&lt;/p&gt;

&lt;h2 id=&quot;forward-propagation&quot;&gt;Forward Propagation&lt;/h2&gt;

&lt;p&gt;Will then go over the basic idea of forward prop, sending data into input node, how values move from each layer via multiplying by weights and biases to achieve a value in the output layer.&lt;/p&gt;

    <pubDate>Thu, 01 Dec 2016 13:23:14 -0700</pubDate>
    <lastBuildDate>Thu, 01 Dec 2016 13:23:14 -0700</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Neural Net Backwards Propagation</title>
        <description>&lt;p&gt;&lt;em&gt;Post coming soon!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Dec 2016 14:11:30 +0000</pubDate>
        <link>http://yourdomain.com/blog/2016/12/01/neural-net-backpropagation.html</link>
        <guid isPermaLink="true">http://yourdomain.com/blog/2016/12/01/neural-net-backpropagation.html</guid>
        
        
      </item>
    
      <item>
        <title>Neural Net Basics and Forward Propagation</title>
        <description>&lt;p&gt;&lt;em&gt;Post coming soon!&lt;/em&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 23 Nov 2016 14:11:30 +0000</pubDate>
        <link>http://yourdomain.com/blog/2016/11/23/neural-net-basics-and-forward-propagation.html</link>
        <guid isPermaLink="true">http://yourdomain.com/blog/2016/11/23/neural-net-basics-and-forward-propagation.html</guid>
        
        
      </item>
    
      <item>
        <title>Intro &amp; Project Goals</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;As students at Turing School of Software &amp;amp; Design, Brian Heim and I are involved in a machine learning group. Near the end of the program, students are able to do a personal project. Brian and I chose to pool our resources to build a neural net from scratch.&lt;/p&gt;

&lt;h2 id=&quot;project-goals&quot;&gt;Project Goals&lt;/h2&gt;
&lt;p&gt;The goal we picked for our neural net was to predict fantasy football scores. This is an interesting problem, yet something we believe we can accomplish in the two weeks given for personal projects. While there are many fantasy football predictions with more time, money and data than us, this does not decrease our learning.&lt;/p&gt;

&lt;p&gt;Learning about machine learning can be intimidating, and we want to make it more accessible. Additionally, given the relatively short timeframe students are at Turing it is difficult to maintain an institutional memory. By making this into a website, we hope to offer a resource to future students.&lt;/p&gt;

&lt;p&gt;Given this, the goals of this project are (in order) -&lt;/p&gt;

&lt;h4 id=&quot;learn-how-to-build-a-neural-net&quot;&gt;1. Learn how to build a neural net&lt;/h4&gt;

&lt;h4 id=&quot;document-our-process-for-future-students-of-machine-learning&quot;&gt;2. Document our process for future students of machine learning&lt;/h4&gt;

&lt;h4 id=&quot;accurately-predict-fantasy-football-scores&quot;&gt;3. Accurately predict fantasy football scores&lt;/h4&gt;

&lt;h2 id=&quot;data&quot;&gt;Data&lt;/h2&gt;

&lt;p&gt;The data used for this project is taken from the &lt;a href=&quot;http://api.fantasy.nfl.com/v1/docs/service?serviceName=playersStats&quot;&gt;NFL Fantasy API&lt;/a&gt;. The initial plan is to divide this up by player and position. Four weeks of stats for a player will be taken as input data, with an output of the fifth week’s fantasy football score. With ~27,000 individual week performances, we believe we have sufficient data to train our neural net. However, with only 3,100 individual week performances for quarter backs, we may not be able to predict this position very accurately&lt;/p&gt;
</description>
        <pubDate>Thu, 03 Nov 2016 19:20:30 +0000</pubDate>
        <link>http://yourdomain.com/blog/2016/11/03/intro-and-project-goals.html</link>
        <guid isPermaLink="true">http://yourdomain.com/blog/2016/11/03/intro-and-project-goals.html</guid>
        
        
      </item>
    
  </channel>
</rss>
